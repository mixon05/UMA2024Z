{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "df = pd.read_csv(path + '/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"Time\")\n",
    "scaler = StandardScaler()\n",
    "for col in df.columns:\n",
    "    if col == \"Class\":\n",
    "        continue\n",
    "    df[col] = scaler.fit_transform(df[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(columns=\"Class\"), df[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = y.value_counts()\n",
    "minority_class = class_counts.idxmin()\n",
    "minority_count = class_counts.min()\n",
    "majority_class = class_counts.idxmax()\n",
    "\n",
    "desired_ratio = 2\n",
    "majority_count = minority_count * desired_ratio\n",
    "sampling_strategy = {\n",
    "    minority_class: minority_count,\n",
    "    majority_class: majority_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=17)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Imbalance ratio in training set: {(y_train.count()-np.sum(y_train))/np.sum(y_train)}\")\n",
    "print(f\"Class proportion in testing set: {(y_test.count()-np.sum(y_test))/np.sum(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new smaller training data set that has both classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "labeled_X = pd.DataFrame()\n",
    "labeled_y = pd.Series()\n",
    "chosen_indexes = []\n",
    "chosen_0_class = 0\n",
    "chosen_1_class = 0\n",
    "for i in y_train.index.tolist():\n",
    "    class_value = y_train.loc[i]\n",
    "    if class_value == 0 and chosen_0_class < desired_ratio:\n",
    "        chosen_0_class += 1\n",
    "    elif class_value == 1 and chosen_1_class < 1:\n",
    "        chosen_1_class += 1\n",
    "    elif chosen_0_class == desired_ratio and chosen_1_class == 1:\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "    labeled_X = pd.concat([labeled_X, X_train.loc[[i]]])\n",
    "    X_train = X_train.drop(i)\n",
    "    labeled_y = pd.concat([labeled_y, y_train.loc[[i]]])\n",
    "    y_train = y_train.drop(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_class_probability(binary_proba):\n",
    "    single_values = []\n",
    "    for proba in binary_proba:\n",
    "        single_values.append(round(proba[1], 4))\n",
    "    return single_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learning(labeled_X, labeled_y, X_train, y_train, model, iterations, save_path):\n",
    "    # Struktura wyników\n",
    "    results = {\n",
    "        \"training_set_size\": len(X_train),\n",
    "        \"test_set_size\": len(X_test),\n",
    "        \"count_of_minority_class_members\": int(y_train.sum()),\n",
    "        \"true_labels\": [int(i) for i in y_test.values],\n",
    "        \"models\": []\n",
    "    }\n",
    "\n",
    "    # Główna pętla uczenia\n",
    "    for i in range(iterations):\n",
    "        model.fit(labeled_X, labeled_y)\n",
    "        \n",
    "        test_proba = model.predict_proba(X_test)\n",
    "        one_class_proba = get_one_class_probability(test_proba)\n",
    "        model_result = {\"training instances\": len(labeled_y), \n",
    "                        \"predictions\": one_class_proba,\n",
    "                        \"minority_class_examples_used\": sum(labeled_y)}\n",
    "        results[\"models\"].append(model_result)\n",
    "        \n",
    "        probabilities = model.predict_proba(X_train)\n",
    "        uncertainty = np.abs(probabilities[:, 0] - probabilities[:, 1])\n",
    "        least_confident_index = np.argmin(uncertainty)\n",
    "        least_confident_sample = X_train.iloc[least_confident_index]\n",
    "        df_index_number = least_confident_sample.name\n",
    "        \n",
    "        labeled_X = pd.concat([labeled_X, least_confident_sample.to_frame().T])\n",
    "        labeled_y = pd.concat([labeled_y, y_train.loc[[df_index_number]]])\n",
    "        X_train = X_train.drop(df_index_number)\n",
    "        y_train = y_train.drop(df_index_number)\n",
    "        print(f\"{i}/{iterations-1}\")\n",
    "\n",
    "    # Zapis do pliku\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def passive_learning(labeled_X, labeled_y, X_train, y_train, model, iterations, save_path):\n",
    "    # Struktura wyników\n",
    "    results = {\n",
    "        \"training_set_size\": len(X_train),\n",
    "        \"test_set_size\": len(X_test),\n",
    "        \"count_of_minority_class_members\": int(y_train.sum()),\n",
    "        \"true_labels\": [int(i) for i in y_test.values],\n",
    "        \"models\": []\n",
    "    }\n",
    "\n",
    "    # Główna pętla uczenia\n",
    "    for i in range(iterations):\n",
    "        model.fit(labeled_X, labeled_y)\n",
    "        \n",
    "        test_proba = model.predict_proba(X_test)\n",
    "        one_class_proba = get_one_class_probability(test_proba)\n",
    "        model_result = {\"training instances\": len(labeled_y), \n",
    "                        \"predictions\": one_class_proba,\n",
    "                        \"minority_class_examples_used\": sum(labeled_y)}\n",
    "        results[\"models\"].append(model_result)\n",
    "        \n",
    "    random_record = X_train.sample(n=1)\n",
    "    labeled_X = pd.concat([labeled_X, random_record])\n",
    "    labeled_y = pd.concat([labeled_y, y_train.loc[random_record.index]])\n",
    "    \n",
    "    X_train = X_train.drop(random_record.index)\n",
    "    y_train = y_train.drop(random_record.index)\n",
    "    \n",
    "    print(f\"{i}/{iterations-1}\")\n",
    "\n",
    "    # Zapis do pliku\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Active Learning for SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learning(\n",
    "    labeled_X=labeled_X,\n",
    "    labeled_y=labeled_y,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    model=SVC(kernel=\"rbf\", probability=True, cache_size=1000),\n",
    "    iterations=300,\n",
    "    save_path=f\"one_positive_class/rbf_active_learning_IR{desired_ratio}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passive learing for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_learning(\n",
    "    labeled_X=labeled_X,\n",
    "    labeled_y=labeled_y,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    model=SVC(kernel=\"rbf\", probability=True, cache_size=1000),\n",
    "    iterations=300,\n",
    "    save_path=f\"one_positive_class/rbf_passive_learning_IR{desired_ratio}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Active learning for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learning(\n",
    "    labeled_X=labeled_X,\n",
    "    labeled_y=labeled_y,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    model=MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42),\n",
    "    iterations=300,\n",
    "    save_path=f\"one_positive_class_nn/active_learning_IR{desired_ratio}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passive learning for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_learning(\n",
    "    labeled_X=labeled_X,\n",
    "    labeled_y=labeled_y,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    model=MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42),\n",
    "    iterations=300,\n",
    "    save_path=f\"one_positive_class_nn/passive_learning_IR{desired_ratio}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42)\n",
    "passive_model.fit(X_train, y_train)\n",
    "    \n",
    "test_proba = passive_model.predict_proba(X_test)\n",
    "one_class_proba = get_one_class_probability(test_proba)\n",
    "results = {\n",
    "        \"training_set_size\": len(X_train),\n",
    "        \"test_set_size\": len(X_test),\n",
    "        \"minority_class_count\": int(np.sum(y_train)),\n",
    "        \"true labels\": [int(i) for i in y_test.values],\n",
    "        \"model\": {\n",
    "            \"predictions\": one_class_proba,\n",
    "            \"minority_class_examples_used\": int(np.sum(y_train))\n",
    "        }\n",
    "    }\n",
    "\n",
    "with open(f\"full_training/rbf_passive_learning_IR{desired_ratio}.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(results, json_file, ensure_ascii=False, indent=4, separators=(',', ': '))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
