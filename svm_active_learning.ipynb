{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "df = pd.read_csv(path + '/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"Time\")\n",
    "scaler = StandardScaler()\n",
    "for col in df.columns:\n",
    "    if col == \"Class\":\n",
    "        continue\n",
    "    df[col] = scaler.fit_transform(df[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(columns=\"Class\"), df[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = y.value_counts()\n",
    "minority_class = class_counts.idxmin()\n",
    "minority_count = class_counts.min()\n",
    "majority_class = class_counts.idxmax()\n",
    "\n",
    "desired_ratio = 256\n",
    "majority_count = minority_count * desired_ratio\n",
    "sampling_strategy = {\n",
    "    minority_class: minority_count,\n",
    "    majority_class: majority_count\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=17)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Imbalance ratio in training set: {(y_train.count()-np.sum(y_train))/np.sum(y_train)}\")\n",
    "print(f\"Class proportion in testing set: {(y_test.count()-np.sum(y_test))/np.sum(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new smaller training data set that has both classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "labeled_X = pd.DataFrame()\n",
    "labeled_y = pd.Series()\n",
    "chosen_indexes = []\n",
    "chosen_0_class = 0\n",
    "chosen_1_class = 0\n",
    "for i in y_train.index.tolist():\n",
    "    class_value = y_train.loc[i]\n",
    "    if class_value == 0 and chosen_0_class < desired_ratio:\n",
    "        chosen_0_class += 1\n",
    "    elif class_value == 1 and chosen_1_class < 1:\n",
    "        chosen_1_class += 1\n",
    "    elif chosen_0_class == desired_ratio and chosen_1_class == 1:\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "    labeled_X = pd.concat([labeled_X, X_train.loc[[i]]])\n",
    "    X_train = X_train.drop(i)\n",
    "    labeled_y = pd.concat([labeled_y, y_train.loc[[i]]])\n",
    "    y_train = y_train.drop(i)\n",
    "    \n",
    "    \n",
    "\n",
    "# while not (labeled_y_sum > 0 and len(labeled_y) != labeled_y_sum):\n",
    "#     random_index = rng.choice(y_train.index.tolist())\n",
    "#     labeled_y = pd.concat([labeled_y, y_train.loc[[random_index]]])\n",
    "#     y_train = y_train.drop(random_index)\n",
    "#     labeled_X = pd.concat([labeled_X, X_train.loc[[random_index]]])\n",
    "#     X_train = X_train.drop(random_index)\n",
    "#     labeled_y_sum = np.sum(labeled_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_class_probability(binary_proba):\n",
    "    single_values = []\n",
    "    for proba in binary_proba:\n",
    "        single_values.append(round(proba[1], 4))\n",
    "    return single_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_X_active = deepcopy(labeled_X)\n",
    "labeled_X_passive = deepcopy(labeled_X)\n",
    "labeled_y_active = deepcopy(labeled_y)\n",
    "labeled_y_passive = deepcopy(labeled_y)\n",
    "\n",
    "unlabeled_X_active = deepcopy(X_train)\n",
    "unlabeled_X_passive = deepcopy(X_train)\n",
    "unlabeled_y_active = deepcopy(y_train)\n",
    "unlabeled_y_passive = deepcopy(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Active Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERS = 300\n",
    "results = {\n",
    "    \"training set size\": len(X_train),\n",
    "    \"count of minority class members\": int(np.sum(y_train)),\n",
    "    \"true labels\": [int(i) for i in y_test.values],\n",
    "    \"models\": []}\n",
    "active_model = SVC(kernel=\"rbf\", probability=True, cache_size=1000)\n",
    "for i in range(ITERS):\n",
    "    active_model.fit(labeled_X_active, labeled_y_active)\n",
    "    \n",
    "    test_proba = active_model.predict_proba(X_test)\n",
    "    one_class_proba = get_one_class_probability(test_proba)\n",
    "    model = {\"training instances\": len(labeled_y_active), \n",
    "             \"predictions\": one_class_proba,\n",
    "             \"minority_class_examples_used\": sum(labeled_y_active)}\n",
    "    results[\"models\"].append(model)\n",
    "    \n",
    "    probabilities = active_model.predict_proba(unlabeled_X_active)\n",
    "    uncertainty = np.abs(probabilities[:, 0] - probabilities[:, 1])\n",
    "    least_confident_index = np.argmin(uncertainty)\n",
    "    least_confident_sample = unlabeled_X_active.iloc[least_confident_index]\n",
    "    df_index_number = least_confident_sample.name\n",
    "    \n",
    "    labeled_X_active = pd.concat([labeled_X_active, least_confident_sample.to_frame().T])\n",
    "    labeled_y_active = pd.concat([labeled_y_active, unlabeled_y_active.loc[[df_index_number]]])\n",
    "    unlabeled_X_active = unlabeled_X_active.drop(df_index_number)\n",
    "    unlabeled_y_active = unlabeled_y_active.drop(df_index_number)\n",
    "    print(f\"{i}/{ITERS-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"one_positive_class/rbf_active_learning_IR{desired_ratio}.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(results, json_file, ensure_ascii=False, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERS = 300\n",
    "results = {\n",
    "    \"training set size\": len(X_train),\n",
    "    \"count of minority class members\": int(np.sum(y_train)),\n",
    "    \"true labels\": [int(i) for i in y_test.values],\n",
    "    \"models\": []}\n",
    "active_model = SVC(kernel=\"rbf\", probability=True, cache_size=1000)\n",
    "for i in range(ITERS):\n",
    "    active_model.fit(labeled_X_passive, labeled_y_passive)\n",
    "    \n",
    "    test_proba = active_model.predict_proba(X_test)\n",
    "    one_class_proba = get_one_class_probability(test_proba)\n",
    "    model = {\"training instances\": len(labeled_y_passive), \n",
    "             \"predictions\": one_class_proba,\n",
    "             \"minority_class_examples_used\": sum(labeled_y_passive)}\n",
    "    results[\"models\"].append(model)\n",
    "    \n",
    "    random_record = unlabeled_X_passive.sample(n=1)\n",
    "    labeled_X_passive = pd.concat([labeled_X_passive, random_record])\n",
    "    labeled_y_passive = pd.concat([labeled_y_passive, unlabeled_y_passive.loc[random_record.index]])\n",
    "    \n",
    "    unlabeled_X_passive = unlabeled_X_passive.drop(random_record.index)\n",
    "    unlabeled_y_passive = unlabeled_y_passive.drop(random_record.index)\n",
    "    \n",
    "    print(f\"{i}/{ITERS-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"one_positive_class/rbf_passive_learning_IR{desired_ratio}.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(results, json_file, ensure_ascii=False, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Active learning for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERS = 300\n",
    "\n",
    "results = {\n",
    "    \"training set size\": len(X_train),\n",
    "    \"count of minority class members\": int(np.sum(y_train)),\n",
    "    \"true labels\": [int(i) for i in y_test.values],\n",
    "    \"models\": []\n",
    "}\n",
    "\n",
    "active_model = MLPClassifier(hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42)\n",
    "\n",
    "for i in range(ITERS):\n",
    "    active_model.fit(labeled_X_active, labeled_y_active)\n",
    "    \n",
    "    test_proba = active_model.predict_proba(X_test)\n",
    "    one_class_proba = get_one_class_probability(test_proba)\n",
    "    model = {\"training instances\": len(labeled_y_active), \n",
    "             \"predictions\": one_class_proba,\n",
    "             \"minority_class_examples_used\": sum(labeled_y_active)}\n",
    "    results[\"models\"].append(model)\n",
    "    \n",
    "    probabilities = active_model.predict_proba(unlabeled_X_active)\n",
    "    uncertainty = np.abs(probabilities[:, 0] - probabilities[:, 1])\n",
    "    least_confident_index = np.argmin(uncertainty)\n",
    "    least_confident_sample = unlabeled_X_active.iloc[least_confident_index]\n",
    "    df_index_number = least_confident_sample.name\n",
    "    \n",
    "    labeled_X_active = pd.concat([labeled_X_active, least_confident_sample.to_frame().T])\n",
    "    labeled_y_active = pd.concat([labeled_y_active, unlabeled_y_active.loc[[df_index_number]]])\n",
    "    unlabeled_X_active = unlabeled_X_active.drop(df_index_number)\n",
    "    unlabeled_y_active = unlabeled_y_active.drop(df_index_number)\n",
    "    print(f\"{i}/{ITERS-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"one_positive_class_nn/active_learning_IR{desired_ratio}.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(results, json_file, ensure_ascii=False, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERS = 300\n",
    "\n",
    "results = {\n",
    "    \"training set size\": len(X_train),\n",
    "    \"count of minority class members\": int(np.sum(y_train)),\n",
    "    \"true labels\": [int(i) for i in y_test.values],\n",
    "    \"models\": []\n",
    "}\n",
    "\n",
    "active_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42)\n",
    "\n",
    "for i in range(ITERS):\n",
    "    active_model.fit(labeled_X_passive, labeled_y_passive)\n",
    "    \n",
    "    test_proba = active_model.predict_proba(X_test)\n",
    "    one_class_proba = get_one_class_probability(test_proba)\n",
    "    model = {\"training instances\": len(labeled_y_passive), \n",
    "             \"predictions\": one_class_proba,\n",
    "             \"minority_class_examples_used\": sum(labeled_y_passive)}\n",
    "    results[\"models\"].append(model)\n",
    "    \n",
    "    random_record = unlabeled_X_passive.sample(n=1)\n",
    "    labeled_X_passive = pd.concat([labeled_X_passive, random_record])\n",
    "    labeled_y_passive = pd.concat([labeled_y_passive, unlabeled_y_passive.loc[random_record.index]])\n",
    "    \n",
    "    unlabeled_X_passive = unlabeled_X_passive.drop(random_record.index)\n",
    "    unlabeled_y_passive = unlabeled_y_passive.drop(random_record.index)\n",
    "    \n",
    "    print(f\"{i}/{ITERS-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"one_positive_class_nn/passive_learning_IR{desired_ratio}.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(results, json_file, ensure_ascii=False, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(10, 10), max_iter=1000, random_state=42)\n",
    "passive_model.fit(X_train, y_train)\n",
    "    \n",
    "test_proba = passive_model.predict_proba(X_test)\n",
    "one_class_proba = get_one_class_probability(test_proba)\n",
    "results = {\n",
    "        \"training_set_size\": len(X_train),\n",
    "        \"test_set_size\": len(X_test),\n",
    "        \"minority_class_count\": int(np.sum(y_train)),\n",
    "        \"true labels\": [int(i) for i in y_test.values],\n",
    "        \"model\": {\n",
    "            \"predictions\": one_class_proba,\n",
    "            \"minority_class_examples_used\": int(np.sum(y_train))\n",
    "        }\n",
    "    }\n",
    "\n",
    "with open(f\"full_training/nn_passive_learning_IR{desired_ratio}.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(results, json_file, ensure_ascii=False, indent=4, separators=(',', ': '))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
